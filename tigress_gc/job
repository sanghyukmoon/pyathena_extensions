#!/bin/bash
#SBATCH --job-name=ppB100  # create a short name for your job
#SBATCH --nodes=1                  # node count
#SBATCH --ntasks=1                 # total number of tasks across all nodes
#SBATCH --cpus-per-task=50         # cpu-cores per task (>1 if multi-threaded tasks)
#SBATCH --partition=bigmem
#SBATCH --mail-type=end,fail
#SBATCH --mail-user=sanghyuk.moon@princeton.edu
#SBATCH --mem-per-cpu=80G               # memory per node
#SBATCH --time=24:00:00          # total run time limit (HH:MM:SS)

module purge
module load anaconda3/2022.5
conda activate pyathena

# === Edit here ============
#TASK="--run-grid"
TASK="--linewidth-size -o"
MODEL=${SLURM_JOB_NAME#pp}
# ==========================

# single jobs
cmd="--unbuffered python do_tasks.py $MODEL $TASK --np $SLURM_CPUS_PER_TASK"
#cmd="--unbuffered python do_tasks.py $MODEL $TASK --np $SLURM_CPUS_PER_TASK --pid-start 31 --pid-end 40"
#cmd="--unbuffered python do_tasks.py M5J2P${SLURM_ARRAY_TASK_ID}N512 -o -t --np $SLURM_CPUS_PER_TASK"

echo $cmd
srun $cmd

# Notes on memory usage
# ---------------------
# grid-denro
# 512  ~ 5 GB per core
